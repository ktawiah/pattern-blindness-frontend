[
  {
    "id": "550e8400-e29b-41d4-a716-446655440001",
    "name": "Two Pointers",
    "description": "Use two pointers to traverse a data structure, typically from opposite ends or at different speeds.",
    "category": "TwoPointers",
    "whatItIs": "Two Pointers is a powerful algorithmic technique that uses two references (pointers) to traverse a data structure, typically an array or string, in a coordinated manner. The pointers can move in various patterns: towards each other from opposite ends, in the same direction at different speeds (fast and slow), or in tandem while maintaining a fixed distance. This technique is particularly effective because it reduces the need for nested loops, transforming O(n²) brute force solutions into O(n) linear time solutions. The key insight is that by maintaining two positions and making intelligent decisions about which pointer to move based on the current state, you can efficiently explore the solution space without examining every possible pair or subset.",
    "whenToUse": "Use Two Pointers when: (1) The input is sorted or has an inherent ordering that allows you to make decisions based on comparisons - this is crucial as it enables you to eliminate large portions of the search space. (2) You need to find pairs, triplets, or subarrays that satisfy a specific condition (sum, product, distance). (3) The problem involves in-place array manipulation where extra space is limited. (4) You're checking for palindromes or symmetric properties. (5) You need to merge, partition, or rearrange elements based on a condition. (6) The problem asks to remove or modify elements while iterating. (7) You're dealing with linked lists and need to detect cycles or find middle elements. The technique is especially powerful when the problem hints at finding relationships between elements at different positions.",
    "whyItWorks": "Two Pointers works because it exploits the ordered nature of data to make intelligent elimination decisions. When data is sorted, comparing elements at two positions gives you information about what direction to search next. For example, if the sum of two elements is too large, you know moving the right pointer left will only produce smaller or equal sums. This monotonic property means each pointer movement eliminates possibilities, ensuring you don't miss any valid solutions while avoiding redundant checks. The technique also works for the fast-slow pointer variant because the mathematical relationship between their speeds creates predictable collision points in cyclic structures.",
    "commonUseCases": [
      "Two Sum in sorted array - Find pair that sums to target",
      "Container with most water - Maximize area between vertical lines",
      "Palindrome check - Verify string reads same forwards and backwards",
      "Remove duplicates from sorted array - In-place deduplication",
      "Merge sorted arrays - Combine two sorted sequences",
      "Trapping rain water - Calculate water volume between heights",
      "3Sum problem - Find all unique triplets that sum to zero",
      "Linked list cycle detection - Floyd's cycle detection algorithm",
      "Remove nth node from end - One-pass linked list manipulation",
      "Sort colors (Dutch National Flag) - Three-way partitioning"
    ],
    "timeComplexity": "O(n)",
    "spaceComplexity": "O(1)",
    "pseudoCode": "OPPOSITE ENDS APPROACH:\nfunction twoSum(arr, target):\n    left = 0\n    right = arr.length - 1\n    \n    while left < right:\n        currentSum = arr[left] + arr[right]\n        \n        if currentSum == target:\n            return [left, right]\n        else if currentSum < target:\n            left++  // Need larger sum\n        else:\n            right--  // Need smaller sum\n    \n    return null\n\nFAST-SLOW POINTER APPROACH:\nfunction hasCycle(head):\n    if head == null: return false\n    \n    slow = head\n    fast = head\n    \n    while fast != null and fast.next != null:\n        slow = slow.next       // Move 1 step\n        fast = fast.next.next  // Move 2 steps\n        \n        if slow == fast:\n            return true  // Cycle detected\n    \n    return false\n\nSAME DIRECTION SLIDING:\nfunction removeDuplicates(arr):\n    if arr.length == 0: return 0\n    \n    writePos = 1  // Position to write next unique\n    \n    for readPos in 1 to arr.length:\n        if arr[readPos] != arr[readPos-1]:\n            arr[writePos] = arr[readPos]\n            writePos++\n    \n    return writePos",
    "triggerSignals": [
      "Problem mentions 'sorted array' or 'sorted list'",
      "Asked to find pair/triplet with specific sum or condition",
      "Question asks for palindrome verification",
      "Need in-place modification with O(1) extra space",
      "Problem involves partitioning or rearranging",
      "Linked list problem asking for cycle detection",
      "Find middle element or kth element from end",
      "Merge two sorted sequences",
      "Problem has 'two elements' or 'pairs' in description",
      "Asked to remove duplicates in-place"
    ],
    "commonMistakes": [
      "Off-by-one errors: Forgetting that the condition is 'left < right' not 'left <= right' when pointers shouldn't meet. Using '<=' can cause checking the same element twice in pair-finding problems.",
      "Not handling duplicates: In problems like 3Sum, failing to skip duplicate values leads to duplicate triplets in the result. Always check if current element equals previous before processing.",
      "Wrong pointer movement: Moving both pointers simultaneously when you should move only one based on the comparison. The movement decision must be deterministic based on the current state.",
      "Incorrect initialization: Starting pointers at wrong positions (e.g., both at 0 when they should be at opposite ends). Fast pointer should start at head.next, not head, in some cycle detection variants.",
      "Missing edge cases: Not handling arrays with fewer than 2 elements, null pointers in linked lists, or empty strings. Always validate input size.",
      "Forgetting to sort: Two pointers on sorted data won't work if you forget to sort first. The O(n log n) sorting cost is still better than O(n²) brute force.",
      "Breaking ties incorrectly: When sum equals target with duplicates, need specific logic to handle which pointer to move to avoid infinite loops."
    ],
    "resources": [
      {
        "title": "Two Pointers - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440002",
    "name": "Sliding Window",
    "description": "Maintain a window of elements that slides through the data structure to find optimal subarrays/substrings.",
    "category": "SlidingWindow",
    "whatItIs": "Sliding Window is an optimization technique that maintains a contiguous subset of elements (the 'window') and efficiently slides it through an array or string to solve problems involving subarrays or substrings. The technique comes in two main flavors: Fixed-size windows (where the window size is constant, like 'maximum sum of k consecutive elements') and Variable-size windows (where the window expands and contracts based on conditions, like 'longest substring without repeating characters'). The power of this technique lies in its ability to avoid recomputing the same information repeatedly - instead of recalculating everything for each new window position from scratch (which would be O(n×k) or O(n²)), we incrementally update by adding the new element entering the window and removing the old element leaving it (achieving O(n)). This makes it ideal for problems that ask about contiguous sequences meeting certain criteria.",
    "whenToUse": "Use Sliding Window when: (1) The problem explicitly asks about contiguous subarrays or substrings - keywords like 'consecutive', 'contiguous', or 'substring' are strong indicators. (2) You need to find maximum/minimum length, maximum/minimum sum, or count of subarrays meeting a condition. (3) The problem involves finding the optimal window (longest, shortest, or with specific properties) within a sequence. (4) You're asked to maintain or track something over a range that moves through the data. (5) There's a fixed window size k and you need statistics (max, min, avg) for each window. (6) The problem requires checking every possible subarray - sliding window can optimize this from O(n²) to O(n). (7) You need to track character frequencies, sums, or counts within a moving range. The technique is particularly effective when the window's validity can be determined efficiently as elements enter and leave.",
    "whyItWorks": "Sliding Window works by exploiting the overlap between consecutive subarrays. When you move the window one position to the right, most of the elements (k-1 out of k in fixed windows) remain the same. Instead of reprocessing all these elements, you only need to: (1) Remove the contribution of the element leaving the window, (2) Add the contribution of the element entering the window, and (3) Update your tracking variables accordingly. This incremental update is O(1) for most operations (sum, count, frequency map operations), making the overall algorithm O(n). For variable windows, the expansion and contraction logic ensures that each element is processed at most twice (once when entering, once when leaving), maintaining linear time complexity. The technique essentially trades space (storing window state) for time (avoiding recomputation).",
    "commonUseCases": [
      "Longest substring without repeating characters - Variable window with hashmap",
      "Minimum window substring - Variable window finding smallest containing target",
      "Maximum sum subarray of size k - Fixed window with running sum",
      "Longest substring with at most k distinct characters - Variable window tracking frequency",
      "Permutation in string - Fixed window matching character counts",
      "Find all anagrams - Fixed window with frequency comparison",
      "Longest repeating character replacement - Variable window with k replacements allowed",
      "Maximum of all subarrays of size k - Fixed window with deque optimization",
      "Minimum size subarray sum - Variable window to find shortest with sum >= target",
      "Fruits into baskets - Variable window with 2 distinct types allowed"
    ],
    "timeComplexity": "O(n)",
    "spaceComplexity": "O(k) for tracking window contents, O(1) for simple sum/count",
    "pseudoCode": "FIXED WINDOW APPROACH:\nfunction maxSumSubarray(arr, k):\n    if arr.length < k: return null\n    \n    // Calculate first window\n    windowSum = 0\n    for i in 0 to k:\n        windowSum += arr[i]\n    \n    maxSum = windowSum\n    \n    // Slide window\n    for i in k to arr.length:\n        windowSum = windowSum - arr[i-k] + arr[i]\n        maxSum = max(maxSum, windowSum)\n    \n    return maxSum\n\nVARIABLE WINDOW (EXPANSION/CONTRACTION):\nfunction lengthOfLongestSubstring(s):\n    charSet = new Set()\n    left = 0\n    maxLength = 0\n    \n    for right in 0 to s.length:\n        // Contract window while duplicate exists\n        while s[right] in charSet:\n            charSet.remove(s[left])\n            left++\n        \n        // Expand window\n        charSet.add(s[right])\n        maxLength = max(maxLength, right - left + 1)\n    \n    return maxLength\n\nMINIMUM WINDOW TEMPLATE:\nfunction minWindow(s, t):\n    need = frequencyMap(t)\n    have = new Map()\n    matched = 0\n    left = 0\n    minLen = infinity\n    result = \"\"\n    \n    for right in 0 to s.length:\n        char = s[right]\n        have[char]++\n        \n        if have[char] == need[char]:\n            matched++\n        \n        // Shrink window while valid\n        while matched == need.size:\n            // Update result if smaller\n            if right - left + 1 < minLen:\n                minLen = right - left + 1\n                result = s[left:right+1]\n            \n            // Remove left char\n            leftChar = s[left]\n            have[leftChar]--\n            if have[leftChar] < need[leftChar]:\n                matched--\n            left++\n    \n    return result",
    "triggerSignals": [
      "Problem mentions 'subarray', 'substring', or 'consecutive elements'",
      "Asked to find maximum/minimum length meeting condition",
      "Question includes 'contiguous sequence' or 'window of size k'",
      "Need to find optimal range (longest/shortest) with property",
      "Problem asks for sum/average/max/min over all windows of size k",
      "Looking for patterns or character frequencies in substrings",
      "Questions like 'at most k distinct' or 'at least k occurrences'",
      "Find smallest/largest subarray with sum meeting threshold",
      "Asked to find anagrams or permutations within a string",
      "Problem involves 'moving through' or 'scanning' a sequence"
    ],
    "commonMistakes": [
      "Forgetting to initialize first window: Must compute the initial window state before sliding. In fixed-size windows, calculate sum/state for first k elements explicitly before the main loop.",
      "Off-by-one in window size: Window size is (right - left + 1), not (right - left). Common error is calculating length incorrectly, especially after contracting the window.",
      "Not updating all tracking variables: When removing elements from the left, must update all state (sum, frequency map, count, etc.). Forgetting even one variable breaks correctness.",
      "Expanding window too eagerly: In variable windows, must check validity after each right expansion and contract immediately if invalid. Don't expand multiple steps before checking.",
      "Incorrect shrinking condition: The while loop condition for contracting must be precise. Using if instead of while causes incomplete shrinking, missing optimal solutions.",
      "Not handling edge cases: Empty arrays, window size larger than array, all elements invalid, single element arrays all need special handling.",
      "Complexity creep: Operations inside the sliding window loop must be O(1) or O(log k). If you're doing O(k) work per iteration, you've lost the optimization and it becomes O(n×k).",
      "Frequency map mistakes: Forgetting to decrement counts when removing from window, or not checking zero counts before removing from map (can cause memory leaks).",
      "Comparison errors: Using > instead of >= or < instead of <= in validity checks can cause off-by-one errors in the result."
    ],
    "resources": [
      {
        "title": "Sliding Window - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440003",
    "name": "Binary Search",
    "description": "Repeatedly divide the search space in half to find target or optimal value in logarithmic time.",
    "category": "BinarySearch",
    "whatItIs": "Binary Search is a highly efficient search algorithm that works on sorted arrays by repeatedly dividing the search interval in half. The core idea is to compare the target value with the middle element: if they match, you've found it; if the target is smaller, search the left half; if larger, search the right half. This halving process continues until the target is found or the search space is exhausted. Beyond just finding exact values, Binary Search can be extended to find boundaries (first/last occurrence), search in rotated arrays, find peaks, and even solve optimization problems by searching the solution space. The algorithm's power comes from its ability to eliminate half the remaining possibilities with each comparison, achieving O(log n) time complexity. This makes it dramatically faster than linear search for large datasets - searching 1 billion elements takes only about 30 comparisons!",
    "whenToUse": "Use Binary Search when: (1) The input array or list is sorted (or can be sorted efficiently). This is the primary requirement - without ordering, binary search cannot make elimination decisions. (2) You need to find an exact value, the first/last occurrence, or insertion position. (3) The problem involves finding a minimum/maximum value that satisfies a condition (binary search on answer). (4) You're searching in a rotated sorted array or mountain array where partial order exists. (5) The search space is vast and linear search would be too slow (O(n) → O(log n) improvement). (6) You need to find a threshold or boundary where a property changes from false to true (monotonic function). (7) Asked to minimize/maximize something subject to constraints (capacity to ship packages, minimum in rotated array, kth smallest element in matrix). (8) The problem mentions 'sorted', 'ordered', or gives you sorted input. (9) You need efficient search in infinite or very large arrays. (10) The problem is an optimization problem that can be formulated as 'can we achieve X?' where X can be binary searched.",
    "whyItWorks": "Binary Search works because of the monotonic property of sorted data. When you compare with the middle element, the comparison gives you definitive information about which half could possibly contain your target. Since the array is sorted, if target is less than middle, it CANNOT be in the right half; if greater, it CANNOT be in the left half. This guarantee allows safely discarding half the search space with each iteration. The logarithmic time comes from dividing problem size by 2 repeatedly: n → n/2 → n/4 → n/8 ... until reaching 1. The number of divisions needed is log₂(n). Even for binary search on answer problems, the principle is the same - you're searching a monotonic solution space where feasibility is preserved in one direction.",
    "commonUseCases": [
      "Find element in sorted array",
      "Find first/last position",
      "Kth element",
      "Capacity to ship packages",
      "Search in rotated sorted array",
      "Find peak element",
      "Square root of integer",
      "Koko eating bananas",
      "Search 2D matrix",
      "Median of two sorted arrays"
    ],
    "timeComplexity": "O(log n)",
    "spaceComplexity": "O(1)",
    "pseudoCode": "function binarySearch(arr, target):\n    left = 0, right = arr.length - 1\n    while left <= right:\n        mid = left + (right - left) / 2\n        if arr[mid] == target: return mid\n        else if arr[mid] < target: left = mid + 1\n        else: right = mid - 1\n    return -1\n\nBinary Search on Answer:\nfunction minCapacity(weights, days):\n    left = max(weights)\n    right = sum(weights)\n    while left < right:\n        mid = left + (right - left) / 2\n        if canShipInDays(weights, mid, days):\n            right = mid\n        else:\n            left = mid + 1\n    return left",
    "triggerSignals": [
      "Sorted array",
      "Find minimum/maximum that satisfies condition",
      "O(log n) time requirement",
      "Rotated sorted array",
      "Find first/last occurrence",
      "Optimization with monotonic property"
    ],
    "commonMistakes": [
      "Integer overflow in mid calculation: Use left + (right - left) / 2 instead of (left + right) / 2",
      "Wrong boundary update",
      "Off-by-one with <= vs <",
      "Infinite loops from incorrect mid update",
      "Wrong search space initialization for binary search on answers"
    ],
    "resources": [
      {
        "title": "Binary Search - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440004",
    "name": "Depth-First Search (DFS)",
    "description": "Explore as far as possible along each branch before backtracking, used for trees, graphs, and recursive exploration.",
    "category": "Graph",
    "whatItIs": "Depth-First Search (DFS) is a fundamental graph/tree traversal algorithm that explores as deeply as possible along each branch before backtracking. It uses a stack data structure (either explicitly or implicitly through recursion) to remember vertices to visit later. Starting from a source vertex, DFS visits a neighbor, then a neighbor of that neighbor, and so on, going deeper until it reaches a dead end (no unvisited neighbors), at which point it backtracks to the most recent vertex with unvisited neighbors. This strategy is called 'depth-first' because it prioritizes deepening the search before widening it. DFS can be implemented recursively (using the call stack) or iteratively (using an explicit stack). The recursive version is often more intuitive and cleaner, while the iterative version gives more control over memory usage and can avoid stack overflow on very deep graphs.",
    "whenToUse": "Use DFS when: (1) You need to explore ALL paths or possibilities (backtracking problems, finding all solutions). (2) Checking connectivity between nodes or finding connected components. (3) Detecting cycles in directed or undirected graphs. (4) Topological sorting (with modifications). (5) Path-finding where you need the actual path, not just shortest distance. (6) Tree traversals (inorder, preorder, postorder). (7) Solving maze/puzzle problems where you try all possibilities. (8) Detecting strongly connected components (Tarjan's algorithm). (9) The solution is likely to be far from root (problems where BFS would take too long). (10) Memory is constrained (DFS uses O(h) space vs BFS's O(w) where h=height, w=width).",
    "whyItWorks": "DFS works because the stack structure (explicit or call stack) provides natural backtracking. When you hit a dead end, the stack remembers where you came from, allowing you to return and try alternative paths. This makes DFS perfect for problems requiring exhaustive search. The visited set prevents infinite loops in cyclic graphs by marking explored vertices. DFS's depth-first nature means it finds complete paths before exploring alternatives, making it ideal for problems where you need to analyze full paths or detect patterns that require seeing the entire branch.",
    "commonUseCases": [
      "Number of islands - Flood fill with DFS",
      "Path sum in tree - Check if path exists with target sum",
      "Clone graph - Deep copy with visited map",
      "Course schedule - Cycle detection",
      "Word search in grid - DFS with backtracking",
      "All paths from source to target",
      "Validate BST - Inorder DFS check",
      "Surrounded regions - DFS from borders",
      "Keys and rooms - DFS reachability"
    ],
    "timeComplexity": "O(V + E) where V=vertices, E=edges",
    "spaceComplexity": "O(h) for recursion stack where h=height/depth",
    "pseudoCode": "RECURSIVE DFS (GRAPH):\nfunction dfs(node, visited, graph):\n    visited.add(node)\n    process(node)\n    \n    for neighbor in graph[node]:\n        if neighbor not in visited:\n            dfs(neighbor, visited, graph)\n\nDFS WITH PATH TRACKING:\nfunction dfsPath(node, target, path, visited):\n    if node == target:\n        return true\n    \n    visited.add(node)\n    path.append(node)\n    \n    for neighbor in neighbors(node):\n        if neighbor not in visited:\n            if dfsPath(neighbor, target, path, visited):\n                return true\n    \n    path.pop()  // Backtrack\n    return false\n\nITERATIVE DFS:\nfunction dfsIterative(start, graph):\n    stack = [start]\n    visited = set([start])\n    \n    while stack:\n        node = stack.pop()\n        process(node)\n        \n        for neighbor in graph[node]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                stack.append(neighbor)",
    "triggerSignals": [
      "Explore all paths or solutions",
      "Find connected components",
      "Detect cycles in graph",
      "Tree traversal (inorder/preorder/postorder)",
      "Backtracking problems",
      "Path finding where path matters",
      "Flood fill or region problems"
    ],
    "commonMistakes": [
      "Not marking visited before recursive call: Mark as visited immediately when adding to stack/calling recursively, not after. This prevents duplicate processing.",
      "Not handling cycles: In graphs (vs trees), you MUST track visited nodes or you'll have infinite recursion/loops.",
      "Forgetting to backtrack: In problems requiring path tracking or state restoration, must undo changes when backtracking (remove from path, reset state).",
      "Modifying visited set incorrectly: In some problems, need to remove from visited after exploring (when you need multiple paths to same node).",
      "Stack overflow: Very deep recursion can cause stack overflow. Use iterative DFS or increase stack size for deep graphs."
    ],
    "resources": [
      {
        "title": "Graph DFS - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440005",
    "name": "Breadth-First Search (BFS)",
    "description": "Explore all neighbors at present depth before moving to nodes at next depth level, ideal for shortest paths.",
    "category": "Graph",
    "whatItIs": "Breadth-First Search (BFS) is a graph traversal algorithm that explores vertices level by level, visiting all neighbors at the current depth before moving deeper. It uses a queue (FIFO - First In, First Out) to manage which vertices to visit next. Starting from a source vertex, BFS visits all its direct neighbors first (level 1), then all unvisited neighbors of those neighbors (level 2), and so on. This layer-by-layer expansion is like ripples spreading from a stone dropped in water. BFS guarantees finding the shortest path in unweighted graphs because it explores paths in increasing order of length - when you first reach a node, you've found the shortest path to it. This property makes BFS the go-to algorithm for shortest path problems in unweighted graphs and for finding minimum steps/moves/levels in various problems.",
    "whenToUse": "Use BFS when: (1) Finding shortest path in unweighted graphs (THE primary use case - BFS guarantees shortest path). (2) Level-order traversal of trees (process nodes level by level). (3) Finding minimum number of steps, moves, or operations. (4) Finding nodes within k distance/steps from source. (5) Testing bipartiteness of a graph (2-coloring). (6) Finding all nodes in a connected component. (7) Solving puzzle/maze problems asking for minimum moves. (8) Broadcasting/spreading problems (rotting oranges, spreading info). (9) Building level-based structures or ensuring layer-wise processing. (10) When solution is likely close to root (opposite of DFS use case). Note: BFS is NOT suitable for weighted graphs - use Dijkstra instead.",
    "whyItWorks": "BFS works because the queue's FIFO property ensures vertices are visited in order of their distance from the source. When you dequeue a vertex at distance d, you enqueue its unvisited neighbors at distance d+1. This systematic layer-by-layer expansion means when you first discover a vertex, you've found the shortest path to it (in unweighted graphs). No shorter path exists because any other path would require going through at least as many levels. The visited set prevents revisiting nodes and ensures each node is processed once, giving O(V+E) time complexity.",
    "commonUseCases": [
      "Shortest path in maze/grid",
      "Binary tree level order traversal",
      "Rotting oranges - multi-source BFS",
      "Word ladder - minimum transformations",
      "Minimum knight moves on chessboard",
      "Open the lock - minimum turns",
      "01 Matrix - distance to nearest 0",
      "Walls and gates - multi-source distance",
      "Snakes and ladders - minimum moves"
    ],
    "timeComplexity": "O(V + E) where V=vertices, E=edges",
    "spaceComplexity": "O(V) for queue and visited set",
    "pseudoCode": "STANDARD BFS:\nfunction bfs(start, graph):\n    queue = [start]\n    visited = set([start])\n    \n    while queue:\n        node = queue.popleft()\n        process(node)\n        \n        for neighbor in graph[node]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n\nBFS WITH DISTANCE/LEVEL:\nfunction bfsDistance(start):\n    queue = [(start, 0)]  // (node, distance)\n    visited = set([start])\n    \n    while queue:\n        node, dist = queue.popleft()\n        \n        if isTarget(node):\n            return dist\n        \n        for neighbor in neighbors(node):\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append((neighbor, dist + 1))\n    \n    return -1\n\nMULTI-SOURCE BFS:\nfunction multiSourceBFS(sources):\n    queue = sources  // Start with all sources\n    visited = set(sources)\n    level = 0\n    \n    while queue:\n        size = len(queue)\n        for _ in range(size):\n            node = queue.popleft()\n            process(node, level)\n            \n            for neighbor in neighbors(node):\n                if neighbor not in visited:\n                    visited.add(neighbor)\n                    queue.append(neighbor)\n        level += 1",
    "triggerSignals": [
      "Find 'shortest path' in unweighted graph",
      "'Minimum steps', 'minimum moves', 'fewest operations'",
      "'Level-order traversal' for trees",
      "'Nearest', 'closest', or 'minimum distance' in grid/graph",
      "Problems with 'spreading' or 'propagation'",
      "'All nodes at distance k' from source",
      "Grid problems asking for shortest path"
    ],
    "commonMistakes": [
      "Using DFS for shortest path: DFS doesn't guarantee shortest path. The first path found by DFS may not be shortest. Always use BFS for unweighted shortest path.",
      "Not marking visited before enqueue: Must add to visited WHEN ENQUEUEING, not when dequeuing. Otherwise, nodes get added to queue multiple times, causing O(V²) complexity.",
      "Forgetting level tracking: When you need level/distance, either use tuple (node, dist) or process queue in chunks (all nodes at current level before next).",
      "Wrong queue implementation: Using deque.pop() instead of popleft(), or list.pop(0) which is O(n). Use collections.deque for O(1) operations.",
      "Not handling multi-source correctly: For problems starting from multiple sources (like rotting oranges), add ALL sources to queue initially with same level."
    ],
    "resources": [
      {
        "title": "Graph BFS - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440006",
    "name": "Dynamic Programming",
    "description": "Break down problems into overlapping subproblems and store solutions to avoid redundant computation.",
    "category": "DynamicProgramming",
    "whatItIs": "Dynamic Programming (DP) is a powerful optimization technique that solves complex problems by breaking them down into simpler overlapping subproblems, solving each subproblem once, and storing their solutions to avoid redundant computation (memoization). DP is applicable when a problem has two key properties: (1) Optimal Substructure - the optimal solution can be constructed from optimal solutions of subproblems, and (2) Overlapping Subproblems - the same subproblems are solved multiple times in a naive recursive approach. DP can be implemented using top-down (recursion + memoization) or bottom-up (iterative tabulation) approaches. Top-down starts with the original problem and recursively breaks it down, caching results. Bottom-up builds solutions iteratively from base cases. DP transforms exponential time algorithms into polynomial time by eliminating redundant calculations, making previously intractable problems solvable.",
    "whenToUse": "Use DP when: (1) Problem asks to count number of ways to do something (count all possibilities). (2) Find minimum or maximum value/cost (optimization). (3) Making sequential decisions where each decision depends on previous decisions. (4) Problem can be broken into overlapping subproblems. (5) Naive recursion leads to repeated calculations (fibonacci is classic example). (6) Problem involves finding optimal path/sequence/subset. (7) Keywords like 'maximize profit', 'minimize cost', 'longest/shortest', 'count ways'. (8) Problems involving choices at each step (take/skip, buy/sell). (9) String matching or subsequence problems. (10) Game theory problems with optimal play. The key is identifying the state (what parameters define a subproblem) and the recurrence relation (how subproblems relate).",
    "whyItWorks": "DP works by exploiting the overlap between subproblems. In naive recursion, the same subproblem might be solved thousands or millions of times. By storing (memoizing) the result the first time we solve it, all subsequent encounters return the cached value in O(1) time. This transforms the time complexity dramatically - for example, naive recursive Fibonacci is O(2^n), but with memoization it becomes O(n). The space-time tradeoff (using extra memory to store results) yields exponential speedup. DP essentially organizes computation to ensure each unique subproblem is solved exactly once.",
    "commonUseCases": [
      "Fibonacci sequence - Classic overlapping subproblems",
      "Climbing stairs - Count ways with memoization",
      "House robber - Max sum with constraints",
      "Coin change - Minimum coins or count ways",
      "Knapsack problem - 0/1 and unbounded variants",
      "Longest Common Subsequence (LCS)",
      "Edit distance - Minimum edits to transform strings",
      "Longest Increasing Subsequence (LIS)",
      "Matrix chain multiplication",
      "Rod cutting problem",
      "Partition equal subset sum",
      "Word break problem",
      "Decode ways"
    ],
    "timeComplexity": "Varies - often O(n*m) for 2D DP, O(n^2) for many problems",
    "spaceComplexity": "O(n) to O(n*m) depending on dimensions, can often optimize to O(1) or O(n)",
    "pseudoCode": "TOP-DOWN (RECURSION + MEMOIZATION):\nfunction fibonacci(n, memo = {}):\n    if n in memo:\n        return memo[n]\n    if n <= 1:\n        return n\n    \n    memo[n] = fibonacci(n-1, memo) + fibonacci(n-2, memo)\n    return memo[n]\n\nBOTTOM-UP (TABULATION):\nfunction coinChange(coins, amount):\n    dp = array of size (amount+1) filled with infinity\n    dp[0] = 0  // Base case\n    \n    for i in 1 to amount:\n        for coin in coins:\n            if coin <= i:\n                dp[i] = min(dp[i], dp[i-coin] + 1)\n    \n    return dp[amount] if dp[amount] != infinity else -1\n\n2D DP (KNAPSACK):\nfunction knapsack(weights, values, capacity):\n    n = len(weights)\n    dp = 2D array[n+1][capacity+1]\n    \n    for i in 0 to n:\n        for w in 0 to capacity:\n            if i == 0 or w == 0:\n                dp[i][w] = 0\n            elif weights[i-1] <= w:\n                dp[i][w] = max(\n                    values[i-1] + dp[i-1][w-weights[i-1]],\n                    dp[i-1][w]\n                )\n            else:\n                dp[i][w] = dp[i-1][w]\n    \n    return dp[n][capacity]\n\nSTANDARD DP STEPS:\n1. Define state (what parameters define subproblem)\n2. Identify base cases (smallest subproblems)\n3. Write recurrence relation (how to combine subproblems)\n4. Determine computation order (topological order of dependencies)\n5. Optimize space if possible (often can reduce dimensions)",
    "triggerSignals": [
      "'Count number of ways' to do something",
      "'Minimum/maximum cost/value/length'",
      "'Longest/shortest sequence/substring'",
      "Making choices at each step (take/skip pattern)",
      "Problem has recursive structure with overlap",
      "'Optimize', 'maximize profit', 'minimize cost'",
      "String manipulation (subsequence, matching, transform)",
      "Partition or subset sum problems",
      "Path counting in grid/matrix",
      "Game theory with optimal strategy"
    ],
    "commonMistakes": [
      "Wrong base case: Base cases are the foundation - if these are wrong, entire DP solution fails. Carefully identify simplest cases (empty string, 0 items, etc.).",
      "Incorrect recurrence relation: The heart of DP. Must correctly express how to build solution from subproblems. Draw examples and verify manually.",
      "Wrong state definition: State must capture all information needed to solve subproblem. Missing parameters leads to wrong results.",
      "Array index out of bounds: Off-by-one errors in DP table dimensions or access are extremely common. Be careful with 0-indexing vs 1-indexing.",
      "Not handling edge cases: Empty inputs, size 1 inputs, negative numbers, zero values all need special consideration.",
      "Forgetting to optimize space: Many 2D DP problems can be solved with O(n) space instead of O(n^2) by using rolling array or two rows.",
      "Using wrong loop order: In bottom-up DP, must compute subproblems before problems that depend on them. Wrong order gives incorrect results.",
      "Memoization but modifying cached values: Once memoized, result shouldn't change. Modifying cached results causes bugs.",
      "Not considering all transitions: In recurrence, must consider all possible choices/transitions from current state."
    ],
    "resources": [
      {
        "title": "DP - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440007",
    "name": "Backtracking",
    "description": "Build solutions incrementally, abandoning paths that fail to satisfy constraints.",
    "category": "Backtracking",
    "whatItIs": "Backtracking is a systematic algorithmic technique for finding all (or some) solutions to computational problems by incrementally building candidates and abandoning (backtracking from) each partial candidate as soon as it determines the candidate cannot lead to a valid solution. It's essentially a refined brute force approach that prunes the search space. The algorithm makes a choice, recursively explores that choice, and if it doesn't work out (violates constraints or leads to invalid solutions), it undoes that choice (backtracks) and tries the next option. This choose-explore-unchoose pattern continues until all possibilities are exhausted. Backtracking is the go-to technique for constraint satisfaction problems, combinatorial optimization, and puzzle solving where you need enumerate all solutions or find any valid solution under constraints.",
    "whenToUse": "Use Backtracking when: (1) Need to generate ALL solutions (permutations, combinations, subsets). (2) Problem involves making a sequence of decisions under constraints. (3) Problem is about finding ANY valid solution satisfying constraints (Sudoku, N-Queens). (4) Need to explore all possible paths/configurations. (5) Problem asks for 'all possible ways' or 'count all solutions'. (6) Constraint satisfaction problems (placing items with restrictions). (7) Puzzle solving (crossword, maze with restrictions). (8) Generating valid strings/sequences (balanced parentheses, IP addresses). (9) Partitioning problems (split array into valid subsets). The key indicator is needing exhaustive search with the ability to prune invalid branches early.",
    "whyItWorks": "Backtracking works by systematically exploring the entire solution space while intelligently pruning branches that cannot lead to valid solutions. The pruning is crucial - by checking constraints as you build the solution incrementally, you can abandon an entire subtree of possibilities as soon as a violation is detected, avoiding wasted exploration of billions of invalid paths. Without pruning, complete enumeration would be intractable. The recursive structure naturally handle the 'undo' operation - as the recursion unwinds, the previous state is restored. This makes backtracking both complete (finds all solutions) and efficient (prunes impossible branches).",
    "commonUseCases": [
      "N-Queens - Place N queens on N×N chessboard",
      "Sudoku solver - Fill board satisfying constraints",
      "Generate all permutations - All arrangements of elements",
      "Generate all combinations - All C(n,k) subsets",
      "Combination sum - Find all combinations summing to target",
      "Word search in grid - Find word following path",
      "Palindrome partitioning - All ways to partition into palindromes",
      "Letter combinations of phone number",
      "Restore IP addresses - Valid IP from digits",
      "Subsets - Generate power set",
      "Generate parentheses - All valid combinations"
    ],
    "timeComplexity": "O(b^d) where b=branching factor, d=depth; often O(n!) or O(2^n)",
    "spaceComplexity": "O(d) for recursion stack plus O(solution size) for path tracking",
    "pseudoCode": "STANDARD BACKTRACKING TEMPLATE:\nfunction backtrack(state, choices, constraints):\n    if isComplete(state):\n        results.add(copy(state))\n        return\n    \n    for choice in choices:\n        if isValid(choice, state, constraints):\n            // Choose\n            makeChoice(state, choice)\n            \n            // Explore\n            backtrack(state, nextChoices, constraints)\n            \n            // Unchoose (backtrack)\n            undoChoice(state, choice)\n\nPERMUTATIONS:\nfunction permute(nums, path, used, result):\n    if len(path) == len(nums):\n        result.add(copy(path))\n        return\n    \n    for i in 0 to len(nums):\n        if used[i]: continue\n        \n        used[i] = true\n        path.append(nums[i])\n        \n        permute(nums, path, used, result)\n        \n        path.pop()\n        used[i] = false\n\nCOMBINATIONS:\nfunction combine(n, k, start, path, result):\n    if len(path) == k:\n        result.add(copy(path))\n        return\n    \n    for i in start to n+1:\n        path.append(i)\n        combine(n, k, i+1, path, result)  // Note: i+1 avoids reuse\n        path.pop()\n\nCONSTRAINT PRUNING:\nfunction solveSudoku(board):\n    for row in 0 to 9:\n        for col in 0 to 9:\n            if board[row][col] == '.': \n                for digit in '1' to '9':\n                    if isValid(board, row, col, digit):\n                        board[row][col] = digit\n                        \n                        if solveSudoku(board):\n                            return true\n                        \n                        board[row][col] = '.'  // Backtrack\n                \n                return false  // No valid digit found\n    \n    return true  // All cells filled",
    "triggerSignals": [
      "'Generate ALL permutations/combinations/subsets'",
      "'Find all solutions' or 'count all ways'",
      "Constraint satisfaction (N-Queens, Sudoku)",
      "'All possible arrangements/configurations'",
      "Making sequence of choices with backtracking",
      "Puzzle solving with constraints",
      "'Partition into valid groups'",
      "Path finding with obstacle/constraint checking"
    ],
    "commonMistakes": [
      "Forgetting to backtrack/undo changes: THE most common mistake. After exploring a choice, you MUST undo it before trying the next choice. Otherwise state corrupts and gives wrong results.",
      "Not making a copy when saving solution: When adding path/state to results, must add a COPY, not the reference. The reference will be modified by subsequent backtracking.",
      "Incorrect base case: Base case determines when you've found a complete solution. Wrong condition means incomplete or invalid solutions get added.",
      "Forgetting to pass updated state: When recursing, ensure you pass the modified state (like start+1 for combinations to avoid reusing elements).",
      "Not pruning early enough: Check constraints as soon as possible. Waiting until base case wastes time exploring doomed branches.",
      "Modifying input incorrectly: Some problems require modifying input (like Sudoku board). Must track what to undo. Using wrong undo logic breaks solution.",
      "Wrong loop range: In combinations (no reuse), start from current index+1. In permutations (no repeats), skip used elements. Getting this wrong causes duplicates or missing solutions."
    ],
    "resources": [
      {
        "title": "Backtracking - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440008",
    "name": "Heap / Priority Queue",
    "description": "Efficiently maintain and access the minimum or maximum element in a dynamic collection.",
    "category": "Heap",
    "whatItIs": "A Heap is a specialized tree-based data structure that maintains a partial ordering property: in a min-heap, parent nodes are smaller than their children; in a max-heap, parents are larger. This heap property is weaker than complete sorting but much cheaper to maintain - insertions and deletions are O(log n) instead of the O(n) needed to maintain a sorted array. Heaps are typically implemented as complete binary trees stored in arrays, where for node at index i, the left child is at 2i+1 and right child at 2i+2. Priority Queues are the abstract data type that heaps implement, providing quick access (O(1)) to the highest-priority (min or max) element and efficient (O(log n)) insertion and removal. Heaps are the secret sauce behind efficient algorithms for top-K problems, streaming data, task scheduling, and graph algorithms like Dijkstra's.",
    "whenToUse": "Use Heap/Priority Queue when: (1) Need repeated access to minimum or maximum element (K largest/smallest problems). (2) Processing elements in priority order rather than insertion order. (3) Merging K sorted lists/arrays efficiently. (4) Finding median in a data stream (using two heaps). (5) Task scheduling where priority matters. (6) Graph algorithms (Dijkstra's shortest path, Prim's MST). (7) Implementing efficient sorting (heapsort). (8) Finding K-th largest/smallest element. (9) Top K frequent elements. (10) Continuous median calculation. The key insight is when you need 'best so far' tracking in a dynamic set where elements are added/removed frequently.",
    "whyItWorks": "Heaps work by maintaining a weaker invariant than full sorting. The heap property only requires parent ≥ children (max-heap) or parent ≤ children (min-heap), not global ordering. This partial order is sufficient for finding min/max and can be maintained with O(log n) operations via bubble-up (heapify-up) after insertion and bubble-down (heapify-down) after deletion. The tree height is log n for n elements, so worst-case path length is log n. The array representation is cache-friendly and space-efficient with no pointer overhead. For K-largest problems, maintaining a min-heap of size K means you always have the K largest elements, and checking if a new element belongs takes O(log K) not O(K).",
    "commonUseCases": [
      "Kth largest element in array - Min-heap of size K",
      "Merge K sorted lists - Min-heap of K elements",
      "Find median from data stream - Two heaps (max + min)",
      "Task scheduler with cooldown - Priority queue by priority",
      "Top K frequent elements - Heap of (frequency, element) pairs",
      "Dijkstra's shortest path - Min-heap of (distance, node)",
      "Meeting rooms II - Min-heap of end times",
      "Ugly number - Min-heap for generating sequence",
      "IPO maximize capital - Two heaps for available projects",
      "Sliding window maximum - Deque (not heap) is better but heap works"
    ],
    "timeComplexity": "Insert: O(log n), ExtractMin/Max: O(log n), Peek: O(1), Heapify: O(n)",
    "spaceComplexity": "O(n) for storing n elements",
    "pseudoCode": "MIN-HEAP OPERATIONS:\nclass MinHeap:\n    function insert(val):\n        heap.append(val)\n        bubbleUp(len(heap)-1)\n    \n    function extractMin():\n        if isEmpty(): return null\n        \n        min = heap[0]\n        heap[0] = heap[len(heap)-1]\n        heap.pop()\n        bubbleDown(0)\n        return min\n    \n    function bubbleUp(index):\n        while index > 0:\n            parent = (index-1) // 2\n            if heap[index] < heap[parent]:\n                swap(heap[index], heap[parent])\n                index = parent\n            else:\n                break\n    \n    function bubbleDown(index):\n        while true:\n            smallest = index\n            left = 2*index + 1\n            right = 2*index + 2\n            \n            if left < len(heap) and heap[left] < heap[smallest]:\n                smallest = left\n            if right < len(heap) and heap[right] < heap[smallest]:\n                smallest = right\n            \n            if smallest == index:\n                break\n            \n            swap(heap[index], heap[smallest])\n            index = smallest\n\nK LARGEST ELEMENTS:\nfunction kLargest(arr, k):\n    minHeap = new MinHeap()\n    \n    for num in arr:\n        minHeap.insert(num)\n        if len(minHeap) > k:\n            minHeap.extractMin()\n    \n    return minHeap.toArray()\n\nMERGE K SORTED LISTS:\nfunction mergeKLists(lists):\n    minHeap = new MinHeap()\n    result = []\n    \n    // Initialize heap with first element from each list\n    for i, list in enumerate(lists):\n        if list:\n            minHeap.insert((list.val, i, list))\n    \n    while not minHeap.isEmpty():\n        val, listIdx, node = minHeap.extractMin()\n        result.append(val)\n        \n        if node.next:\n            minHeap.insert((node.next.val, listIdx, node.next))\n    \n    return result",
    "triggerSignals": [
      "'Kth largest' or 'Kth smallest' element",
      "'Top K' anything (frequent, largest, smallest)",
      "'Merge K sorted' lists/arrays",
      "'Find median' from stream or dynamic data",
      "Need to 'continuously find min/max' as elements change",
      "Task/event scheduling with priorities",
      "'Process in priority order'",
      "Graph algorithms (Dijkstra,Prim)"
    ],
    "commonMistakes": [
      "Using wrong heap type: For K largest elements, use MIN-heap (counterintuitive!). For K smallest, use MAX-heap. The heap stores the K items and kicks out worst one, so heap top is the threshold.",
      "Not handling heap size carefully: When maintaining size K, must check size AFTER inserting, not before. Insert first, then pop if size > K.",
      "Forgetting to negate for max-heap: In languages with only min-heap (like Python's heapq), negate values to simulate max-heap: insert(-val), extract, then negate again.",
      "Comparing wrong elements in tuples: When using (priority, value) tuples, ensure the comparison element is first. Python compares tuples lexicographically.",
      "Not handling equal priorities: When priorities are equal, need tiebreaker (like insertion order) or you'll get comparison errors with non-comparable objects.",
      "Building heap inefficiently: heapify() is O(n) but adding elements one-by-one is O(n log n). Use heapify when possible.",
      "Using heap for every sliding window: Heaps work but deque is often better for sliding window problems with specific patterns."
    ],
    "resources": [
      {
        "title": "Heaps - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440009",
    "name": "Greedy",
    "description": "Make locally optimal choices at each step, hoping to find a global optimum.",
    "category": "Greedy",
    "whatItIs": "Greedy algorithms make the best choice at each step without considering future consequences.",
    "whenToUse": "Use Greedy when: Problem has greedy choice property, Local optimal leads to global optimal",
    "whyItWorks": "For certain problems, locally optimal choice is part of globally optimal solution",
    "commonUseCases": [
      "Activity selection",
      "Jump game",
      "Gas station",
      "Non-overlapping intervals"
    ],
    "timeComplexity": "O(n log n)",
    "spaceComplexity": "O(1)",
    "pseudoCode": "Identify greedy choice, sort, make greedy selections...",
    "triggerSignals": [
      "Maximize/minimize with constraints",
      "Interval problems",
      "Sorting might help"
    ],
    "commonMistakes": [
      "Applying greedy when DP needed",
      "Wrong sorting criteria"
    ],
    "resources": [
      {
        "title": "Greedy Algorithms",
        "url": "https://www.geeksforgeeks.org/",
        "type": "article"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440010",
    "name": "Monotonic Stack",
    "description": "Maintain a stack with elements in sorted order to efficiently solve next greater/smaller element problems.",
    "category": "MonotonicStack",
    "whatItIs": "A Monotonic Stack maintains elements in increasing or decreasing order.",
    "whenToUse": "Use when: Finding next/previous greater/smaller element, Stock span problems, Largest rectangle",
    "whyItWorks": "Each element pushed/popped once, O(1) amortized per element",
    "commonUseCases": [
      "Next greater element",
      "Daily temperatures",
      "Largest rectangle",
      "Trapping rain water"
    ],
    "timeComplexity": "O(n)",
    "spaceComplexity": "O(n)",
    "pseudoCode": "Maintain monotonic property while processing elements...",
    "triggerSignals": [
      "Next/greater smaller element",
      "Span problems",
      "Subarray min/max sums"
    ],
    "commonMistakes": [
      "Wrong monotonic direction",
      "Storing values instead of indices"
    ],
    "resources": [
      {
        "title": "Monotonic Stack - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440011",
    "name": "Union-Find (Disjoint Set)",
    "description": "Track connected components with near O(1) union and find operations.",
    "category": "UnionFind",
    "whatItIs": "Union-Find maintains disjoint sets with efficient union and find operations.",
    "whenToUse": "Use when: Tracking connected components, Determining set membership, Kruskal's MST, Cycle detection",
    "whyItWorks": "Path compression and union by rank achieve O(α(n)) amortized time",
    "commonUseCases": [
      "Number of connected components",
      "Redundant connection",
      "Accounts merge",
      "Making a large island"
    ],
    "timeComplexity": "O(α(n))",
    "spaceComplexity": "O(n)",
    "pseudoCode": "Find with path compression, union by rank...",
    "triggerSignals": [
      "Connected components",
      "Group membership",
      "Merge groups",
      "Cycle detection undirected"
    ],
    "commonMistakes": [
      "Forgetting path compression",
      "Not using union by rank"
    ],
    "resources": [
      {
        "title": "Union Find - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440012",
    "name": "Trie (Prefix Tree)",
    "description": "Tree structure for efficient storage and retrieval of strings with prefix-based operations.",
    "category": "Trie",
    "whatItIs": "A Trie is a tree where paths from root form prefixes of stored strings.",
    "whenToUse": "Use when: Prefix-based search, Autocomplete, Word search in grid, Spell checking",
    "whyItWorks": "Common prefixes stored once, search time O(m) independent of dictionary size",
    "commonUseCases": [
      "Implement Trie",
      "Word search II",
      "Search suggestions",
      "Design add and search",
      "Palindrome pairs"
    ],
    "timeComplexity": "O(m)",
    "spaceComplexity": "O(total characters)",
    "pseudoCode": "Insert with node creation, search with traversal...",
    "triggerSignals": [
      "Prefix search",
      "Autocomplete",
      "Word dictionary",
      "Multiple string search"
    ],
    "commonMistakes": [
      "Forgetting is_end flag",
      "Not handling empty strings"
    ],
    "resources": [
      {
        "title": "Trie - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440013",
    "name": "Intervals",
    "description": "Techniques for handling overlapping intervals: merging, finding gaps, and scheduling.",
    "category": "Intervals",
    "whatItIs": "Interval problems involve ranges with common operations like merging and finding overlaps.",
    "whenToUse": "Use when: Dealing with time ranges, Meeting room scheduling, Merging ranges, Finding overlaps",
    "whyItWorks": "Sorting allows linear processing of overlaps",
    "commonUseCases": [
      "Merge intervals",
      "Insert interval",
      "Meeting rooms",
      "Non-overlapping intervals"
    ],
    "timeComplexity": "O(n log n)",
    "spaceComplexity": "O(n)",
    "pseudoCode": "Sort by start, merge overlapping intervals...",
    "triggerSignals": [
      "Time ranges",
      "Overlapping intervals",
      "Merge ranges",
      "Meeting scheduling"
    ],
    "commonMistakes": [
      "Wrong sort key",
      "Not merging all overlaps"
    ],
    "resources": [
      {
        "title": "Intervals - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440014",
    "name": "Divide and Conquer",
    "description": "Break problem into smaller subproblems, solve recursively, and combine results.",
    "category": "DivideAndConquer",
    "whatItIs": "Divide and Conquer breaks problems into independent subproblems and combines solutions.",
    "whenToUse": "Use when: Problem breaks into independent subproblems, Solutions combine efficiently",
    "whyItWorks": "Smaller problems are easier, recursion handles division, combining is often O(n)",
    "commonUseCases": [
      "Merge Sort",
      "Quick Sort",
      "Binary Search",
      "Maximum subarray",
      "Closest pair of points"
    ],
    "timeComplexity": "O(n log n)",
    "spaceComplexity": "O(n)",
    "pseudoCode": "Base case, divide, conquer recursively, combine...",
    "triggerSignals": [
      "Problem can be halved",
      "Subproblems are independent",
      "Sorting algorithms"
    ],
    "commonMistakes": [
      "Wrong base case",
      "Inefficient combine step"
    ],
    "resources": [
      {
        "title": "Divide and Conquer - Khan Academy",
        "url": "https://www.khanacademy.org/",
        "type": "article"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440015",
    "name": "Topological Sort",
    "description": "Linear ordering of vertices in a DAG where every directed edge u→v has u before v.",
    "category": "Graph",
    "whatItIs": "Topological Sort produces linear ordering of vertices in a Directed Acyclic Graph.",
    "whenToUse": "Use when: Processing dependencies, Build systems, Course prerequisites, Task scheduling",
    "whyItWorks": "In a DAG, there's always a vertex with no incoming edges",
    "commonUseCases": [
      "Course Schedule",
      "Alien Dictionary",
      "Build order",
      "Task scheduling",
      "Package dependencies"
    ],
    "timeComplexity": "O(V + E)",
    "spaceComplexity": "O(V)",
    "pseudoCode": "Kahn's algorithm with indegree or DFS approach...",
    "triggerSignals": [
      "Dependencies/prerequisites",
      "Build order",
      "Course schedule",
      "Cycle detection"
    ],
    "commonMistakes": [
      "Forgetting to check for cycles",
      "Wrong indegree calculation"
    ],
    "resources": [
      {
        "title": "Topological Sort - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440016",
    "name": "Bit Manipulation",
    "description": "Use bitwise operations to solve problems efficiently with constant space.",
    "category": "BitManipulation",
    "whatItIs": "Bit manipulation uses bitwise operators to solve problems at the bit level.",
    "whenToUse": "Use when: Finding single/unique numbers, Power of 2 checks, Counting bits, Generating subsets",
    "whyItWorks": "XOR properties: x^x=0, x^0=x, operations are O(1)",
    "commonUseCases": [
      "Single Number",
      "Number of 1 Bits",
      "Power of Two",
      "Counting Bits",
      "Subsets"
    ],
    "timeComplexity": "O(1)",
    "spaceComplexity": "O(1)",
    "pseudoCode": "AND, OR, XOR operations, bit shifting...",
    "triggerSignals": [
      "Find unique/single number",
      "Power of 2",
      "Binary representation",
      "O(1) space"
    ],
    "commonMistakes": [
      "Sign bit issues",
      "Wrong shift direction"
    ],
    "resources": [
      {
        "title": "Bit Manipulation - NeetCode",
        "url": "https://neetcode.io/",
        "type": "course"
      }
    ]
  }
]